{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import stop_words\n",
    "stopWordsList=list(stop_words.ENGLISH_STOP_WORDS)\n",
    "from string import punctuation as punc\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import time\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('C:\\\\Users\\\\Bilal\\\\Downloads\\\\IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = corpus.iloc[: , [0]] .values\n",
    "labels = corpus.iloc[:, [1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = review.flatten()\n",
    "reviews = x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempList=[]\n",
    "stemmingList=[]\n",
    "finalList=[]\n",
    "joinOn=\" \"\n",
    "tempSplit=[]\n",
    "\n",
    "for rev in reviews:\n",
    "    tempStr=rev.replace('<br /><br />','')\n",
    "    tempList=tempStr.split(\" \")\n",
    "    \n",
    "    remStopWord=[word for word in tempList if word not in stopWordsList] #Removing stop words.\n",
    "    remPunctuation=[word for word in remStopWord if word not in punc]\n",
    "    for word in remPunctuation:\n",
    "        \n",
    "        \n",
    "        stemmingList.append(wl.lemmatize(ps.stem(word),'v')) #Stemming and lemmetizing words.\n",
    "    #Joining words back toghether of the review after preprocessing techniques to make it whole.\n",
    "    joinStr=joinOn.join(stemmingList)\n",
    "    #List that contains reviews after the preprocessing techniques as elements.\n",
    "    finalList.append(joinStr)\n",
    "    stemmingList=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Remove Punctuation.\n",
    "fflist=[]\n",
    "for rev in finalList:\n",
    "    tempWord=\"\"\n",
    "    for char in rev:\n",
    "        if char not in punc:\n",
    "            tempWord=tempWord+char\n",
    "    fflist.append(tempWord)      "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix= CountVectorizer(lowercase=True).fit_transform(fflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bilal\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split (matrix, labels, shuffle = True, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "dtclf = DecisionTreeClassifier()\n",
    "dtclf.fit(train_x, train_y)\n",
    "label = dtclf.predict(test_x)\n",
    "timeX=time.time() - start_time\n",
    "acc = accuracy_score(test_y, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier with default parameters : \n",
      " Time Taken : 71.08480310440063 seconds \n",
      " Accuracy Score :  0.725\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier with default parameters : \\n\",\"Time Taken : %s seconds\" % timeX,\"\\n Accuracy Score : \", acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixE=CountVectorizer(min_df=8,binary=True).fit_transform(fflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bilal\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split (matrixE, labels, shuffle = True, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "dtclf = DecisionTreeClassifier()\n",
    "dtclf.fit(train_x, train_y)\n",
    "label = dtclf.predict(test_x)\n",
    "acc = accuracy_score(test_y, label)\n",
    "timeX=time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier with parameters min_df=8 and binary=True : \n",
      " Time Taken : 45.92359733581543 seconds \n",
      " Accuracy Score :  0.7149333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier with parameters min_df=8 and binary=True : \\n\",\"Time Taken : %s seconds\" % timeX,\"\\n Accuracy Score : \", acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bilal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Bilal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "mLinearClass=SGDClassifier().fit(train_x,train_y)\n",
    "label = mLinearClass.predict(test_x)\n",
    "acc = accuracy_score(test_y, label)\n",
    "timeX=time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear Classifier with : \n",
      " Time Taken : 1.3357386589050293 seconds \n",
      " Accuracy Score :  0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score of Linear Classifier with : \\n\",\"Time Taken : %s seconds\" % timeX,\"\\n Accuracy Score : \", acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : \n",
    "\n",
    "Linear Classifier not only reduces the running time drastically but \n",
    "also pushes the accuracy score above 80%, Linear classifier works best \n",
    "because lables are only of two types positive and Negative \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
